{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   LSTAT  MEDV  \n",
       "0   4.98  24.0  \n",
       "1   9.14  21.6  \n",
       "2   4.03  34.7  \n",
       "3   2.94  33.4  \n",
       "4   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   LSTAT  B  \n",
       "0   4.98  1  \n",
       "1   9.14  1  \n",
       "2   4.03  1  \n",
       "3   2.94  1  \n",
       "4   5.33  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_boston = df.drop(columns=['MEDV'], axis=1)\n",
    "X_boston['B'] = 1\n",
    "Y_boston = df['MEDV']\n",
    "X_boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X_boston.shape[0]\n",
    "X = tf.placeholder(dtype='float32', name='X', shape=[X_boston.shape[0], X_boston.shape[1]])\n",
    "Y = tf.placeholder(dtype='float32', name='Y')\n",
    "\n",
    "thetas = tf.Variable(tf.zeros(shape=[X_boston.shape[1], 1]), 'thetas')\n",
    "\n",
    "y_pred = tf.matmul(X, thetas)\n",
    "loss_function = tf.multiply(tf.divide(1, 2), tf.reduce_mean(tf.pow(Y - y_pred, 2)))\n",
    "loss_summary = tf.summary.scalar(tensor=loss_function, name='loss_summary')\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.000008).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, loss = 157.8068389892578\n",
      "Step: 100, loss = 64.63529968261719\n",
      "Step: 200, loss = 59.009857177734375\n",
      "Step: 300, loss = 56.39996337890625\n",
      "Step: 400, loss = 54.9951286315918\n",
      "Step: 500, loss = 54.08989334106445\n",
      "Step: 600, loss = 53.405948638916016\n",
      "Step: 700, loss = 52.831424713134766\n",
      "Step: 800, loss = 52.320899963378906\n",
      "Step: 900, loss = 51.854270935058594\n",
      "Step: 1000, loss = 51.422786712646484\n",
      "Step: 1100, loss = 51.020606994628906\n",
      "Step: 1200, loss = 50.64517593383789\n",
      "Step: 1300, loss = 50.29356384277344\n",
      "Step: 1400, loss = 49.96427536010742\n",
      "Step: 1500, loss = 49.655479431152344\n",
      "Step: 1600, loss = 49.36539077758789\n",
      "Step: 1700, loss = 49.09270095825195\n",
      "Step: 1800, loss = 48.83600997924805\n",
      "Step: 1900, loss = 48.59465408325195\n",
      "Step: 2000, loss = 48.367061614990234\n",
      "Step: 2100, loss = 48.15237808227539\n",
      "Step: 2200, loss = 47.949893951416016\n",
      "Step: 2300, loss = 47.75837326049805\n",
      "Step: 2400, loss = 47.57746505737305\n",
      "Step: 2500, loss = 47.40652847290039\n",
      "Step: 2600, loss = 47.244667053222656\n",
      "Step: 2700, loss = 47.091102600097656\n",
      "Step: 2800, loss = 46.94567108154297\n",
      "Step: 2900, loss = 46.807682037353516\n",
      "Step: 3000, loss = 46.67680740356445\n",
      "Step: 3100, loss = 46.55244445800781\n",
      "Step: 3200, loss = 46.43415832519531\n",
      "Step: 3300, loss = 46.32176208496094\n",
      "Step: 3400, loss = 46.214839935302734\n",
      "Step: 3500, loss = 46.11299133300781\n",
      "Step: 3600, loss = 46.0159912109375\n",
      "Step: 3700, loss = 45.92357635498047\n",
      "Step: 3800, loss = 45.83549118041992\n",
      "Step: 3900, loss = 45.751468658447266\n",
      "Step: 4000, loss = 45.67140579223633\n",
      "Step: 4100, loss = 45.594635009765625\n",
      "Step: 4200, loss = 45.52168655395508\n",
      "Step: 4300, loss = 45.451744079589844\n",
      "Step: 4400, loss = 45.38478088378906\n",
      "Step: 4500, loss = 45.32113265991211\n",
      "Step: 4600, loss = 45.25994110107422\n",
      "Step: 4700, loss = 45.20158386230469\n",
      "Step: 4800, loss = 45.14567947387695\n",
      "Step: 4900, loss = 45.09194564819336\n",
      "Step: 5000, loss = 45.04069519042969\n",
      "Step: 5100, loss = 44.991615295410156\n",
      "Step: 5200, loss = 44.94438552856445\n",
      "Step: 5300, loss = 44.899009704589844\n",
      "Step: 5400, loss = 44.855918884277344\n",
      "Step: 5500, loss = 44.814212799072266\n",
      "Step: 5600, loss = 44.77423095703125\n",
      "Step: 5700, loss = 44.735931396484375\n",
      "Step: 5800, loss = 44.699283599853516\n",
      "Step: 5900, loss = 44.66377258300781\n",
      "Step: 6000, loss = 44.63006591796875\n",
      "Step: 6100, loss = 44.59746551513672\n",
      "Step: 6200, loss = 44.56607437133789\n",
      "Step: 6300, loss = 44.5358772277832\n",
      "Step: 6400, loss = 44.5070686340332\n",
      "Step: 6500, loss = 44.4791374206543\n",
      "Step: 6600, loss = 44.45236587524414\n",
      "Step: 6700, loss = 44.426780700683594\n",
      "Step: 6800, loss = 44.40188980102539\n",
      "Step: 6900, loss = 44.37801742553711\n",
      "Step: 7000, loss = 44.35505294799805\n",
      "Step: 7100, loss = 44.33290481567383\n",
      "Step: 7200, loss = 44.31153869628906\n",
      "Step: 7300, loss = 44.290985107421875\n",
      "Step: 7400, loss = 44.27125549316406\n",
      "Step: 7500, loss = 44.25225067138672\n",
      "Step: 7600, loss = 44.233795166015625\n",
      "Step: 7700, loss = 44.216121673583984\n",
      "Step: 7800, loss = 44.19907760620117\n",
      "Step: 7900, loss = 44.1824951171875\n",
      "Step: 8000, loss = 44.166664123535156\n",
      "Step: 8100, loss = 44.15129852294922\n",
      "Step: 8200, loss = 44.13655090332031\n",
      "Step: 8300, loss = 44.12215805053711\n",
      "Step: 8400, loss = 44.108482360839844\n",
      "Step: 8500, loss = 44.09516525268555\n",
      "Step: 8600, loss = 44.082183837890625\n",
      "Step: 8700, loss = 44.06986999511719\n",
      "Step: 8800, loss = 44.05781555175781\n",
      "Step: 8900, loss = 44.046287536621094\n",
      "Step: 9000, loss = 44.03512191772461\n",
      "Step: 9100, loss = 44.02434158325195\n",
      "Step: 9200, loss = 44.013755798339844\n",
      "Step: 9300, loss = 44.00349807739258\n",
      "Step: 9400, loss = 43.99367904663086\n",
      "Step: 9500, loss = 43.98411178588867\n",
      "Step: 9600, loss = 43.974937438964844\n",
      "Step: 9700, loss = 43.96592330932617\n",
      "Step: 9800, loss = 43.957584381103516\n",
      "Step: 9900, loss = 43.94908905029297\n",
      "Step: 10000, loss = 43.941036224365234\n",
      "Step: 10100, loss = 43.93310546875\n",
      "Step: 10200, loss = 43.925540924072266\n",
      "Step: 10300, loss = 43.91815185546875\n",
      "Step: 10400, loss = 43.9110221862793\n",
      "Step: 10500, loss = 43.904022216796875\n",
      "Step: 10600, loss = 43.89741897583008\n",
      "Step: 10700, loss = 43.89084243774414\n",
      "Step: 10800, loss = 43.88442611694336\n",
      "Step: 10900, loss = 43.87818908691406\n",
      "Step: 11000, loss = 43.87233352661133\n",
      "Step: 11100, loss = 43.86642074584961\n",
      "Step: 11200, loss = 43.860836029052734\n",
      "Step: 11300, loss = 43.855247497558594\n",
      "Step: 11400, loss = 43.849971771240234\n",
      "Step: 11500, loss = 43.84484100341797\n",
      "Step: 11600, loss = 43.83984375\n",
      "Step: 11700, loss = 43.83494567871094\n",
      "Step: 11800, loss = 43.82993698120117\n",
      "Step: 11900, loss = 43.825382232666016\n",
      "Step: 12000, loss = 43.82097625732422\n",
      "Step: 12100, loss = 43.81656265258789\n",
      "Step: 12200, loss = 43.81217956542969\n",
      "Step: 12300, loss = 43.807960510253906\n",
      "Step: 12400, loss = 43.80400848388672\n",
      "Step: 12500, loss = 43.799835205078125\n",
      "Step: 12600, loss = 43.79594039916992\n",
      "Step: 12700, loss = 43.79229736328125\n",
      "Step: 12800, loss = 43.78836441040039\n",
      "Step: 12900, loss = 43.78489685058594\n",
      "Step: 13000, loss = 43.781349182128906\n",
      "Step: 13100, loss = 43.777923583984375\n",
      "Step: 13200, loss = 43.77448654174805\n",
      "Step: 13300, loss = 43.77127456665039\n",
      "Step: 13400, loss = 43.76799774169922\n",
      "Step: 13500, loss = 43.764869689941406\n",
      "Step: 13600, loss = 43.761714935302734\n",
      "Step: 13700, loss = 43.75863265991211\n",
      "Step: 13800, loss = 43.75569534301758\n",
      "Step: 13900, loss = 43.75271224975586\n",
      "Step: 14000, loss = 43.75001907348633\n",
      "Step: 14100, loss = 43.747161865234375\n",
      "Step: 14200, loss = 43.74449920654297\n",
      "Step: 14300, loss = 43.74181365966797\n",
      "Step: 14400, loss = 43.7391471862793\n",
      "Step: 14500, loss = 43.73657989501953\n",
      "Step: 14600, loss = 43.734153747558594\n",
      "Step: 14700, loss = 43.73176193237305\n",
      "Step: 14800, loss = 43.72932815551758\n",
      "Step: 14900, loss = 43.72703552246094\n",
      "Step: 15000, loss = 43.72452926635742\n",
      "Step: 15100, loss = 43.722251892089844\n",
      "Step: 15200, loss = 43.71998596191406\n",
      "Step: 15300, loss = 43.717796325683594\n",
      "Step: 15400, loss = 43.71560287475586\n",
      "Step: 15500, loss = 43.713523864746094\n",
      "Step: 15600, loss = 43.71149444580078\n",
      "Step: 15700, loss = 43.70939254760742\n",
      "Step: 15800, loss = 43.707359313964844\n",
      "Step: 15900, loss = 43.70528030395508\n",
      "Step: 16000, loss = 43.70332717895508\n",
      "Step: 16100, loss = 43.70133972167969\n",
      "Step: 16200, loss = 43.69948959350586\n",
      "Step: 16300, loss = 43.69767761230469\n",
      "Step: 16400, loss = 43.695701599121094\n",
      "Step: 16500, loss = 43.69387435913086\n",
      "Step: 16600, loss = 43.69197463989258\n",
      "Step: 16700, loss = 43.69026184082031\n",
      "Step: 16800, loss = 43.68854522705078\n",
      "Step: 16900, loss = 43.686622619628906\n",
      "Step: 17000, loss = 43.68490219116211\n",
      "Step: 17100, loss = 43.683197021484375\n",
      "Step: 17200, loss = 43.68150329589844\n",
      "Step: 17300, loss = 43.679805755615234\n",
      "Step: 17400, loss = 43.67828369140625\n",
      "Step: 17500, loss = 43.67677688598633\n",
      "Step: 17600, loss = 43.67521667480469\n",
      "Step: 17700, loss = 43.67360305786133\n",
      "Step: 17800, loss = 43.671932220458984\n",
      "Step: 17900, loss = 43.67047882080078\n",
      "Step: 18000, loss = 43.668949127197266\n",
      "Step: 18100, loss = 43.66740036010742\n",
      "Step: 18200, loss = 43.66592788696289\n",
      "Step: 18300, loss = 43.6643180847168\n",
      "Step: 18400, loss = 43.66294860839844\n",
      "Step: 18500, loss = 43.66154098510742\n",
      "Step: 18600, loss = 43.66005325317383\n",
      "Step: 18700, loss = 43.658756256103516\n",
      "Step: 18800, loss = 43.657466888427734\n",
      "Step: 18900, loss = 43.65607452392578\n",
      "Step: 19000, loss = 43.65464401245117\n",
      "Step: 19100, loss = 43.65327072143555\n",
      "Step: 19200, loss = 43.65184783935547\n",
      "Step: 19300, loss = 43.650428771972656\n",
      "Step: 19400, loss = 43.649085998535156\n",
      "Step: 19500, loss = 43.64768600463867\n",
      "Step: 19600, loss = 43.64643478393555\n",
      "Step: 19700, loss = 43.64523696899414\n",
      "Step: 19800, loss = 43.64387512207031\n",
      "Step: 19900, loss = 43.64257049560547\n",
      "Step: 20000, loss = 43.64138412475586\n",
      "Step: 20100, loss = 43.640079498291016\n",
      "Step: 20200, loss = 43.63889694213867\n",
      "Step: 20300, loss = 43.63770294189453\n",
      "Step: 20400, loss = 43.636592864990234\n",
      "Step: 20500, loss = 43.63526153564453\n",
      "Step: 20600, loss = 43.634037017822266\n",
      "Step: 20700, loss = 43.63285446166992\n",
      "Step: 20800, loss = 43.63166046142578\n",
      "Step: 20900, loss = 43.63043975830078\n",
      "Step: 21000, loss = 43.629295349121094\n",
      "Step: 21100, loss = 43.6281852722168\n",
      "Step: 21200, loss = 43.62702178955078\n",
      "Step: 21300, loss = 43.62587356567383\n",
      "Step: 21400, loss = 43.62466812133789\n",
      "Step: 21500, loss = 43.62351989746094\n",
      "Step: 21600, loss = 43.6224365234375\n",
      "Step: 21700, loss = 43.62135314941406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 21800, loss = 43.6201286315918\n",
      "Step: 21900, loss = 43.61905288696289\n",
      "Step: 22000, loss = 43.617977142333984\n",
      "Step: 22100, loss = 43.61688232421875\n",
      "Step: 22200, loss = 43.61577224731445\n",
      "Step: 22300, loss = 43.61463165283203\n",
      "Step: 22400, loss = 43.61378479003906\n",
      "Step: 22500, loss = 43.612606048583984\n",
      "Step: 22600, loss = 43.61146926879883\n",
      "Step: 22700, loss = 43.61035919189453\n",
      "Step: 22800, loss = 43.609336853027344\n",
      "Step: 22900, loss = 43.60826873779297\n",
      "Step: 23000, loss = 43.60727310180664\n",
      "Step: 23100, loss = 43.60622024536133\n",
      "Step: 23200, loss = 43.60515594482422\n",
      "Step: 23300, loss = 43.604122161865234\n",
      "Step: 23400, loss = 43.60312271118164\n",
      "Step: 23500, loss = 43.60212707519531\n",
      "Step: 23600, loss = 43.60116958618164\n",
      "Step: 23700, loss = 43.60012435913086\n",
      "Step: 23800, loss = 43.59904098510742\n",
      "Step: 23900, loss = 43.598106384277344\n",
      "Step: 24000, loss = 43.59728240966797\n",
      "Step: 24100, loss = 43.59632873535156\n",
      "Step: 24200, loss = 43.59532928466797\n",
      "Step: 24300, loss = 43.59419250488281\n",
      "Step: 24400, loss = 43.59315872192383\n",
      "Step: 24500, loss = 43.59223556518555\n",
      "Step: 24600, loss = 43.59130096435547\n",
      "Step: 24700, loss = 43.590274810791016\n",
      "Step: 24800, loss = 43.589290618896484\n",
      "Step: 24900, loss = 43.588321685791016\n",
      "Step: 25000, loss = 43.587379455566406\n",
      "Step: 25100, loss = 43.586395263671875\n",
      "Step: 25200, loss = 43.58539581298828\n",
      "Step: 25300, loss = 43.58437728881836\n",
      "Step: 25400, loss = 43.583534240722656\n",
      "Step: 25500, loss = 43.58260726928711\n",
      "Step: 25600, loss = 43.5816764831543\n",
      "Step: 25700, loss = 43.580848693847656\n",
      "Step: 25800, loss = 43.57990264892578\n",
      "Step: 25900, loss = 43.578941345214844\n",
      "Step: 26000, loss = 43.57803726196289\n",
      "Step: 26100, loss = 43.57720184326172\n",
      "Step: 26200, loss = 43.57623291015625\n",
      "Step: 26300, loss = 43.57530212402344\n",
      "Step: 26400, loss = 43.57429885864258\n",
      "Step: 26500, loss = 43.57346725463867\n",
      "Step: 26600, loss = 43.57264709472656\n",
      "Step: 26700, loss = 43.5716552734375\n",
      "Step: 26800, loss = 43.57069396972656\n",
      "Step: 26900, loss = 43.56987762451172\n",
      "Step: 27000, loss = 43.5689582824707\n",
      "Step: 27100, loss = 43.56806182861328\n",
      "Step: 27200, loss = 43.567195892333984\n",
      "Step: 27300, loss = 43.56624984741211\n",
      "Step: 27400, loss = 43.56542205810547\n",
      "Step: 27500, loss = 43.56454086303711\n",
      "Step: 27600, loss = 43.56363296508789\n",
      "Step: 27700, loss = 43.562774658203125\n",
      "Step: 27800, loss = 43.56183624267578\n",
      "Step: 27900, loss = 43.5610237121582\n",
      "Step: 28000, loss = 43.560115814208984\n",
      "Step: 28100, loss = 43.559303283691406\n",
      "Step: 28200, loss = 43.558475494384766\n",
      "Step: 28300, loss = 43.55757141113281\n",
      "Step: 28400, loss = 43.55674743652344\n",
      "Step: 28500, loss = 43.55588150024414\n",
      "Step: 28600, loss = 43.55511474609375\n",
      "Step: 28700, loss = 43.554290771484375\n",
      "Step: 28800, loss = 43.553375244140625\n",
      "Step: 28900, loss = 43.55248260498047\n",
      "Step: 29000, loss = 43.5516357421875\n",
      "Step: 29100, loss = 43.550899505615234\n",
      "Step: 29200, loss = 43.54999542236328\n",
      "Step: 29300, loss = 43.54915237426758\n",
      "Step: 29400, loss = 43.548404693603516\n",
      "Step: 29500, loss = 43.54750442504883\n",
      "Step: 29600, loss = 43.5467643737793\n",
      "Step: 29700, loss = 43.54580307006836\n",
      "Step: 29800, loss = 43.54486846923828\n",
      "Step: 29900, loss = 43.54414367675781\n",
      "Step: 30000, loss = 43.543277740478516\n",
      "Step: 30100, loss = 43.542442321777344\n",
      "Step: 30200, loss = 43.54161834716797\n",
      "Step: 30300, loss = 43.54077911376953\n",
      "Step: 30400, loss = 43.53994369506836\n",
      "Step: 30500, loss = 43.53912353515625\n",
      "Step: 30600, loss = 43.53834915161133\n",
      "Step: 30700, loss = 43.5375862121582\n",
      "Step: 30800, loss = 43.536746978759766\n",
      "Step: 30900, loss = 43.53595733642578\n",
      "Step: 31000, loss = 43.53523635864258\n",
      "Step: 31100, loss = 43.53448486328125\n",
      "Step: 31200, loss = 43.533592224121094\n",
      "Step: 31300, loss = 43.53281021118164\n",
      "Step: 31400, loss = 43.53212356567383\n",
      "Step: 31500, loss = 43.53132247924805\n",
      "Step: 31600, loss = 43.53050231933594\n",
      "Step: 31700, loss = 43.52967834472656\n",
      "Step: 31800, loss = 43.52894973754883\n",
      "Step: 31900, loss = 43.52813720703125\n",
      "Step: 32000, loss = 43.52730941772461\n",
      "Step: 32100, loss = 43.52652359008789\n",
      "Step: 32200, loss = 43.52579879760742\n",
      "Step: 32300, loss = 43.524993896484375\n",
      "Step: 32400, loss = 43.52423095703125\n",
      "Step: 32500, loss = 43.523563385009766\n",
      "Step: 32600, loss = 43.522682189941406\n",
      "Step: 32700, loss = 43.52192306518555\n",
      "Step: 32800, loss = 43.52113342285156\n",
      "Step: 32900, loss = 43.5203857421875\n",
      "Step: 33000, loss = 43.519596099853516\n",
      "Step: 33100, loss = 43.518829345703125\n",
      "Step: 33200, loss = 43.51820755004883\n",
      "Step: 33300, loss = 43.51736831665039\n",
      "Step: 33400, loss = 43.51663589477539\n",
      "Step: 33500, loss = 43.51588439941406\n",
      "Step: 33600, loss = 43.515174865722656\n",
      "Step: 33700, loss = 43.514381408691406\n",
      "Step: 33800, loss = 43.51361846923828\n",
      "Step: 33900, loss = 43.51286697387695\n",
      "Step: 34000, loss = 43.51215744018555\n",
      "Step: 34100, loss = 43.5114860534668\n",
      "Step: 34200, loss = 43.51072692871094\n",
      "Step: 34300, loss = 43.509979248046875\n",
      "Step: 34400, loss = 43.50922775268555\n",
      "Step: 34500, loss = 43.50852584838867\n",
      "Step: 34600, loss = 43.507728576660156\n",
      "Step: 34700, loss = 43.50700759887695\n",
      "Step: 34800, loss = 43.506256103515625\n",
      "Step: 34900, loss = 43.50552749633789\n",
      "Step: 35000, loss = 43.50471878051758\n",
      "Step: 35100, loss = 43.50394821166992\n",
      "Step: 35200, loss = 43.50323486328125\n",
      "Step: 35300, loss = 43.50239562988281\n",
      "Step: 35400, loss = 43.501708984375\n",
      "Step: 35500, loss = 43.50095748901367\n",
      "Step: 35600, loss = 43.50025939941406\n",
      "Step: 35700, loss = 43.4995231628418\n",
      "Step: 35800, loss = 43.498802185058594\n",
      "Step: 35900, loss = 43.498069763183594\n",
      "Step: 36000, loss = 43.49736022949219\n",
      "Step: 36100, loss = 43.4965934753418\n",
      "Step: 36200, loss = 43.495845794677734\n",
      "Step: 36300, loss = 43.495140075683594\n",
      "Step: 36400, loss = 43.49448776245117\n",
      "Step: 36500, loss = 43.49370574951172\n",
      "Step: 36600, loss = 43.49311065673828\n",
      "Step: 36700, loss = 43.492393493652344\n",
      "Step: 36800, loss = 43.49161911010742\n",
      "Step: 36900, loss = 43.49078369140625\n",
      "Step: 37000, loss = 43.49018859863281\n",
      "Step: 37100, loss = 43.48940658569336\n",
      "Step: 37200, loss = 43.488704681396484\n",
      "Step: 37300, loss = 43.488006591796875\n",
      "Step: 37400, loss = 43.487300872802734\n",
      "Step: 37500, loss = 43.48664093017578\n",
      "Step: 37600, loss = 43.48600387573242\n",
      "Step: 37700, loss = 43.485225677490234\n",
      "Step: 37800, loss = 43.48450469970703\n",
      "Step: 37900, loss = 43.483699798583984\n",
      "Step: 38000, loss = 43.48310089111328\n",
      "Step: 38100, loss = 43.482391357421875\n",
      "Step: 38200, loss = 43.48168182373047\n",
      "Step: 38300, loss = 43.480934143066406\n",
      "Step: 38400, loss = 43.480228424072266\n",
      "Step: 38500, loss = 43.47956085205078\n",
      "Step: 38600, loss = 43.47893142700195\n",
      "Step: 38700, loss = 43.478240966796875\n",
      "Step: 38800, loss = 43.47745895385742\n",
      "Step: 38900, loss = 43.476806640625\n",
      "Step: 39000, loss = 43.47615051269531\n",
      "Step: 39100, loss = 43.4754753112793\n",
      "Step: 39200, loss = 43.4747428894043\n",
      "Step: 39300, loss = 43.474090576171875\n",
      "Step: 39400, loss = 43.47333908081055\n",
      "Step: 39500, loss = 43.4726448059082\n",
      "Step: 39600, loss = 43.47196578979492\n",
      "Step: 39700, loss = 43.471336364746094\n",
      "Step: 39800, loss = 43.470706939697266\n",
      "Step: 39900, loss = 43.469947814941406\n",
      "Step: 40000, loss = 43.46923065185547\n",
      "Step: 40100, loss = 43.46867752075195\n",
      "Step: 40200, loss = 43.46799850463867\n",
      "Step: 40300, loss = 43.4673957824707\n",
      "Step: 40400, loss = 43.4666748046875\n",
      "Step: 40500, loss = 43.46595764160156\n",
      "Step: 40600, loss = 43.46531295776367\n",
      "Step: 40700, loss = 43.464637756347656\n",
      "Step: 40800, loss = 43.4640007019043\n",
      "Step: 40900, loss = 43.46332550048828\n",
      "Step: 41000, loss = 43.462703704833984\n",
      "Step: 41100, loss = 43.46206283569336\n",
      "Step: 41200, loss = 43.46140670776367\n",
      "Step: 41300, loss = 43.46071243286133\n",
      "Step: 41400, loss = 43.459983825683594\n",
      "Step: 41500, loss = 43.45930480957031\n",
      "Step: 41600, loss = 43.45858383178711\n",
      "Step: 41700, loss = 43.45796203613281\n",
      "Step: 41800, loss = 43.4572868347168\n",
      "Step: 41900, loss = 43.45657730102539\n",
      "Step: 42000, loss = 43.45594787597656\n",
      "Step: 42100, loss = 43.45526123046875\n",
      "Step: 42200, loss = 43.45463562011719\n",
      "Step: 42300, loss = 43.45399475097656\n",
      "Step: 42400, loss = 43.453304290771484\n",
      "Step: 42500, loss = 43.452571868896484\n",
      "Step: 42600, loss = 43.45198440551758\n",
      "Step: 42700, loss = 43.45137023925781\n",
      "Step: 42800, loss = 43.450714111328125\n",
      "Step: 42900, loss = 43.44995880126953\n",
      "Step: 43000, loss = 43.449344635009766\n",
      "Step: 43100, loss = 43.44864273071289\n",
      "Step: 43200, loss = 43.448062896728516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 43300, loss = 43.4473876953125\n",
      "Step: 43400, loss = 43.446773529052734\n",
      "Step: 43500, loss = 43.44614028930664\n",
      "Step: 43600, loss = 43.445499420166016\n",
      "Step: 43700, loss = 43.44483947753906\n",
      "Step: 43800, loss = 43.44419479370117\n",
      "Step: 43900, loss = 43.4436149597168\n",
      "Step: 44000, loss = 43.4429817199707\n",
      "Step: 44100, loss = 43.442440032958984\n",
      "Step: 44200, loss = 43.44179153442383\n",
      "Step: 44300, loss = 43.44105911254883\n",
      "Step: 44400, loss = 43.44040298461914\n",
      "Step: 44500, loss = 43.439735412597656\n",
      "Step: 44600, loss = 43.43910217285156\n",
      "Step: 44700, loss = 43.438480377197266\n",
      "Step: 44800, loss = 43.437862396240234\n",
      "Step: 44900, loss = 43.43723678588867\n",
      "Step: 45000, loss = 43.43665313720703\n",
      "Step: 45100, loss = 43.43598556518555\n",
      "Step: 45200, loss = 43.43535614013672\n",
      "Step: 45300, loss = 43.43467330932617\n",
      "Step: 45400, loss = 43.434051513671875\n",
      "Step: 45500, loss = 43.43342590332031\n",
      "Step: 45600, loss = 43.43273162841797\n",
      "Step: 45700, loss = 43.43212127685547\n",
      "Step: 45800, loss = 43.4315071105957\n",
      "Step: 45900, loss = 43.4309196472168\n",
      "Step: 46000, loss = 43.43027877807617\n",
      "Step: 46100, loss = 43.4296760559082\n",
      "Step: 46200, loss = 43.429073333740234\n",
      "Step: 46300, loss = 43.42850875854492\n",
      "Step: 46400, loss = 43.42786407470703\n",
      "Step: 46500, loss = 43.42721176147461\n",
      "Step: 46600, loss = 43.426597595214844\n",
      "Step: 46700, loss = 43.426025390625\n",
      "Step: 46800, loss = 43.425315856933594\n",
      "Step: 46900, loss = 43.42466735839844\n",
      "Step: 47000, loss = 43.424049377441406\n",
      "Step: 47100, loss = 43.423370361328125\n",
      "Step: 47200, loss = 43.42284393310547\n",
      "Step: 47300, loss = 43.42226791381836\n",
      "Step: 47400, loss = 43.42167282104492\n",
      "Step: 47500, loss = 43.421146392822266\n",
      "Step: 47600, loss = 43.42047119140625\n",
      "Step: 47700, loss = 43.419857025146484\n",
      "Step: 47800, loss = 43.41921615600586\n",
      "Step: 47900, loss = 43.41855239868164\n",
      "Step: 48000, loss = 43.41791915893555\n",
      "Step: 48100, loss = 43.41733932495117\n",
      "Step: 48200, loss = 43.41667556762695\n",
      "Step: 48300, loss = 43.416099548339844\n",
      "Step: 48400, loss = 43.415550231933594\n",
      "Step: 48500, loss = 43.41493225097656\n",
      "Step: 48600, loss = 43.41432571411133\n",
      "Step: 48700, loss = 43.41374588012695\n",
      "Step: 48800, loss = 43.41316223144531\n",
      "Step: 48900, loss = 43.41257858276367\n",
      "Step: 49000, loss = 43.4119873046875\n",
      "Step: 49100, loss = 43.41135787963867\n",
      "Step: 49200, loss = 43.41079330444336\n",
      "Step: 49300, loss = 43.41019058227539\n",
      "Step: 49400, loss = 43.4095344543457\n",
      "Step: 49500, loss = 43.40890121459961\n",
      "Step: 49600, loss = 43.40833282470703\n",
      "Step: 49700, loss = 43.40776443481445\n",
      "Step: 49800, loss = 43.40715026855469\n",
      "Step: 49900, loss = 43.40651321411133\n",
      "Step: 50000, loss = 43.4058952331543\n",
      "Step: 50100, loss = 43.405372619628906\n",
      "Step: 50200, loss = 43.40469741821289\n",
      "Step: 50300, loss = 43.40404510498047\n",
      "Step: 50400, loss = 43.40339279174805\n",
      "Step: 50500, loss = 43.402740478515625\n",
      "Step: 50600, loss = 43.402252197265625\n",
      "Step: 50700, loss = 43.401676177978516\n",
      "Step: 50800, loss = 43.401123046875\n",
      "Step: 50900, loss = 43.4005241394043\n",
      "Step: 51000, loss = 43.39994812011719\n",
      "Step: 51100, loss = 43.399452209472656\n",
      "Step: 51200, loss = 43.39890670776367\n",
      "Step: 51300, loss = 43.3983039855957\n",
      "Step: 51400, loss = 43.39765167236328\n",
      "Step: 51500, loss = 43.39710998535156\n",
      "Step: 51600, loss = 43.39646530151367\n",
      "Step: 51700, loss = 43.395931243896484\n",
      "Step: 51800, loss = 43.39533996582031\n",
      "Step: 51900, loss = 43.3947868347168\n",
      "Step: 52000, loss = 43.39411163330078\n",
      "Step: 52100, loss = 43.39359664916992\n",
      "Step: 52200, loss = 43.39302062988281\n",
      "Step: 52300, loss = 43.39239501953125\n",
      "Step: 52400, loss = 43.39187240600586\n",
      "Step: 52500, loss = 43.391300201416016\n",
      "Step: 52600, loss = 43.390663146972656\n",
      "Step: 52700, loss = 43.390071868896484\n",
      "Step: 52800, loss = 43.38951873779297\n",
      "Step: 52900, loss = 43.38890838623047\n",
      "Step: 53000, loss = 43.38833999633789\n",
      "Step: 53100, loss = 43.38785934448242\n",
      "Step: 53200, loss = 43.38724136352539\n",
      "Step: 53300, loss = 43.38658142089844\n",
      "Step: 53400, loss = 43.38600540161133\n",
      "Step: 53500, loss = 43.38552474975586\n",
      "Step: 53600, loss = 43.384971618652344\n",
      "Step: 53700, loss = 43.38434982299805\n",
      "Step: 53800, loss = 43.383750915527344\n",
      "Step: 53900, loss = 43.383209228515625\n",
      "Step: 54000, loss = 43.382625579833984\n",
      "Step: 54100, loss = 43.38204574584961\n",
      "Step: 54200, loss = 43.38141632080078\n",
      "Step: 54300, loss = 43.38090515136719\n",
      "Step: 54400, loss = 43.38032913208008\n",
      "Step: 54500, loss = 43.379722595214844\n",
      "Step: 54600, loss = 43.37917709350586\n",
      "Step: 54700, loss = 43.378692626953125\n",
      "Step: 54800, loss = 43.3781852722168\n",
      "Step: 54900, loss = 43.37757873535156\n",
      "Step: 55000, loss = 43.376976013183594\n",
      "Step: 55100, loss = 43.376434326171875\n",
      "Step: 55200, loss = 43.37586975097656\n",
      "Step: 55300, loss = 43.375274658203125\n",
      "Step: 55400, loss = 43.374698638916016\n",
      "Step: 55500, loss = 43.374114990234375\n",
      "Step: 55600, loss = 43.37351608276367\n",
      "Step: 55700, loss = 43.372989654541016\n",
      "Step: 55800, loss = 43.37245559692383\n",
      "Step: 55900, loss = 43.371864318847656\n",
      "Step: 56000, loss = 43.37131118774414\n",
      "Step: 56100, loss = 43.37081527709961\n",
      "Step: 56200, loss = 43.37028121948242\n",
      "Step: 56300, loss = 43.36971664428711\n",
      "Step: 56400, loss = 43.36911392211914\n",
      "Step: 56500, loss = 43.36859130859375\n",
      "Step: 56600, loss = 43.36800003051758\n",
      "Step: 56700, loss = 43.36752700805664\n",
      "Step: 56800, loss = 43.366912841796875\n",
      "Step: 56900, loss = 43.366424560546875\n",
      "Step: 57000, loss = 43.365882873535156\n",
      "Step: 57100, loss = 43.365394592285156\n",
      "Step: 57200, loss = 43.36489486694336\n",
      "Step: 57300, loss = 43.364261627197266\n",
      "Step: 57400, loss = 43.3637580871582\n",
      "Step: 57500, loss = 43.36316680908203\n",
      "Step: 57600, loss = 43.3626594543457\n",
      "Step: 57700, loss = 43.36207580566406\n",
      "Step: 57800, loss = 43.36155700683594\n",
      "Step: 57900, loss = 43.36103820800781\n",
      "Step: 58000, loss = 43.36048889160156\n",
      "Step: 58100, loss = 43.35989761352539\n",
      "Step: 58200, loss = 43.35934066772461\n",
      "Step: 58300, loss = 43.358768463134766\n",
      "Step: 58400, loss = 43.35820007324219\n",
      "Step: 58500, loss = 43.357662200927734\n",
      "Step: 58600, loss = 43.35712814331055\n",
      "Step: 58700, loss = 43.35662841796875\n",
      "Step: 58800, loss = 43.35610580444336\n",
      "Step: 58900, loss = 43.35552215576172\n",
      "Step: 59000, loss = 43.35496520996094\n",
      "Step: 59100, loss = 43.35446548461914\n",
      "Step: 59200, loss = 43.35389709472656\n",
      "Step: 59300, loss = 43.35335159301758\n",
      "Step: 59400, loss = 43.35291290283203\n",
      "Step: 59500, loss = 43.35234832763672\n",
      "Step: 59600, loss = 43.35191345214844\n",
      "Step: 59700, loss = 43.35137176513672\n",
      "Step: 59800, loss = 43.35081481933594\n",
      "Step: 59900, loss = 43.35028076171875\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(logdir='./graphs/assignment_2_3_multivariate/loss_summary/')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(60000):\n",
    "        sess.run(optimizer, {X: X_boston, Y: Y_boston})\n",
    "    \n",
    "        if(step % 100 == 0):\n",
    "            loss = sess.run(loss_function, {X: X_boston,Y: Y_boston})\n",
    "            print(\"Step: {0}, loss = {1}\".format(step, loss))\n",
    "            \n",
    "        summary = sess.run(loss_summary, {X: X_boston,Y: Y_boston})\n",
    "        writer.add_summary(summary, step)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
