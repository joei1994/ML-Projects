{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tutorial link: https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This tutorial will teach you how to tackle the imbalanced classification\n",
    "#imbalanced classification is the problem where there are one class in dataset outnumbers other class\n",
    "#imbalanced refer to disparity in target variable\n",
    "#e.g. a dataset contains 100,000 instance, 98% of them are positive class, other 2% are negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why machine learning algorithms struggle with imbalanced dataset\n",
    "#For example, In LogisticRegression which aim to minimize an average error from all instances in dataset\n",
    "##if in that dataset has small portion of positive class, means positive class contribute less compare to negative class which has more instance\n",
    "##so, model trained by minimize error from nagative class more that minimize errors from positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>cls</th><th scope=col>x1</th><th scope=col>x2</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0          </td><td>0.20079810 </td><td> 0.67803761</td></tr>\n",
       "\t<tr><td>0          </td><td>0.01662009 </td><td> 1.57655790</td></tr>\n",
       "\t<tr><td>0          </td><td>0.22872469 </td><td>-0.55953375</td></tr>\n",
       "\t<tr><td>0          </td><td>0.12637877 </td><td>-0.09381378</td></tr>\n",
       "\t<tr><td>0          </td><td>0.60082129 </td><td>-0.29839489</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " cls & x1 & x2\\\\\n",
       "\\hline\n",
       "\t 0           & 0.20079810  &  0.67803761\\\\\n",
       "\t 0           & 0.01662009  &  1.57655790\\\\\n",
       "\t 0           & 0.22872469  & -0.55953375\\\\\n",
       "\t 0           & 0.12637877  & -0.09381378\\\\\n",
       "\t 0           & 0.60082129  & -0.29839489\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "cls | x1 | x2 | \n",
       "|---|---|---|---|---|\n",
       "| 0           | 0.20079810  |  0.67803761 | \n",
       "| 0           | 0.01662009  |  1.57655790 | \n",
       "| 0           | 0.22872469  | -0.55953375 | \n",
       "| 0           | 0.12637877  | -0.09381378 | \n",
       "| 0           | 0.60082129  | -0.29839489 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  cls x1         x2         \n",
       "1 0   0.20079810  0.67803761\n",
       "2 0   0.01662009  1.57655790\n",
       "3 0   0.22872469 -0.55953375\n",
       "4 0   0.12637877 -0.09381378\n",
       "5 0   0.60082129 -0.29839489"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load imbalanced dataset\n",
    "library(ROSE)\n",
    "data(hacide)\n",
    "#hacide are split into train and test set\n",
    "head(hacide.train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>cls</th><th scope=col>x1</th><th scope=col>x2</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0          </td><td> 0.05558898</td><td> 2.09865792</td></tr>\n",
       "\t<tr><td>0          </td><td>-0.74531524</td><td>-2.84903952</td></tr>\n",
       "\t<tr><td>0          </td><td>-0.18493608</td><td> 0.38072888</td></tr>\n",
       "\t<tr><td>0          </td><td>-0.98002974</td><td> 0.01893521</td></tr>\n",
       "\t<tr><td>0          </td><td> 0.10627565</td><td> 0.90209911</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " cls & x1 & x2\\\\\n",
       "\\hline\n",
       "\t 0           &  0.05558898 &  2.09865792\\\\\n",
       "\t 0           & -0.74531524 & -2.84903952\\\\\n",
       "\t 0           & -0.18493608 &  0.38072888\\\\\n",
       "\t 0           & -0.98002974 &  0.01893521\\\\\n",
       "\t 0           &  0.10627565 &  0.90209911\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "cls | x1 | x2 | \n",
       "|---|---|---|---|---|\n",
       "| 0           |  0.05558898 |  2.09865792 | \n",
       "| 0           | -0.74531524 | -2.84903952 | \n",
       "| 0           | -0.18493608 |  0.38072888 | \n",
       "| 0           | -0.98002974 |  0.01893521 | \n",
       "| 0           |  0.10627565 |  0.90209911 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  cls x1          x2         \n",
       "1 0    0.05558898  2.09865792\n",
       "2 0   -0.74531524 -2.84903952\n",
       "3 0   -0.18493608  0.38072888\n",
       "4 0   -0.98002974  0.01893521\n",
       "5 0    0.10627565  0.90209911"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(hacide.test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "980  20 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's look at the skewness in training set\n",
    "table(hacide.train$cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "0.98 0.02 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prop.table(table(hacide.train$cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainn set are serverly skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call: \n",
       "accuracy.meas(response = hacide.test$cls, predicted = y_test_pred[, \n",
       "    2])\n",
       "\n",
       "Examples are labelled as positive when predicted is greater than 0.5 \n",
       "\n",
       "precision: 1.000\n",
       "recall: 0.200\n",
       "F: 0.167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#next, train decision tree clssifier using this skewed data\n",
    "library(rpart)\n",
    "tree_clf <- rpart(cls ~ ., data = hacide.train)\n",
    "\n",
    "#predict the test set\n",
    "y_test_pred <- predict(tree_clf, newdata = hacide.test)\n",
    "\n",
    "#compute model's precision, recall, f1 score\n",
    "accuracy.meas(hacide.test$cls, y_test_pred[, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model has very low recall score mean, it barely recall positive instancesin test set\n",
    "#since recall = TP / (TP + FN), low recall mean high FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area under the curve (AUC): 0.600"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compute model AUC\n",
    "roc.curve(hacide.test$cls, y_test_pred[, 2], plotit = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC score is 0.6 which is very poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "980 980 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now, let's create new balanced dataset using the following techniques\n",
    "#1. Oversmapling (sample more minority class)\n",
    "#2. Undersampling (reduce majority class)\n",
    "#3. Both (apply Over and Under sampling)\n",
    "#4. ROSE (generate new data)\n",
    "\n",
    "#Ovsersampling\n",
    "over_data <- ovun.sample(cls ~ ., hacide.train, method = 'over', N = 1960)$data\n",
    "table(over_data$cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1 \n",
       "20 20 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Undersampling\n",
    "under_data <- ovun.sample(cls ~., data = hacide.train, method = 'under', N = 40, seed = 1)$data\n",
    "table(under_data$cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "520 480 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Both(Over and Under sampling)\n",
    "both_data <- ovun.sample(cls ~ ., data = hacide.train, method = 'both', N = 1000, seed = 1)$data\n",
    "table(both_data$cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "520 480 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ROSE(generate new minority data)\n",
    "rose_data <- ROSE(cls ~., hacide.train, N = 1000, seed = 1)$data\n",
    "table(rose_data$cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, train 4 decision tree classifiers using these balanced data\n",
    "over_tree_clf <- rpart(cls ~., data = over_data)\n",
    "under_tree_clf <- rpart(cls ~., data = under_data)\n",
    "both_tree_clf <- rpart(cls ~., data = both_data)\n",
    "rose_tree_clf <- rpart(cls ~., data = rose_data)\n",
    "\n",
    "#evaluate these model performances using test set\n",
    "test_over_pred <- predict(over_tree_clf, newdata = hacide.test)\n",
    "test_under_pred <- predict(under_tree_clf, newdata = hacide.test)\n",
    "test_both_pred <- predict(both_tree_clf, newdata = hacide.test)\n",
    "test_rose_pred <- predict(rose_tree_clf, newdat = hacide.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area under the curve (AUC): 0.798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AUC score of model trained with Oversampling data\n",
    "roc.curve(hacide.test$cls, test_over_pred[, 2], plotit = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area under the curve (AUC): 0.867"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AUC score of model trained with Undersampoing data\n",
    "roc.curve(hacide.test$cls, test_under_pred[, 2], plotit = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area under the curve (AUC): 0.798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AUC socre of model trained with Both over and under sampoing data\n",
    "roc.curve(hacide.test$cls, test_both_pred[, 2], plotit = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area under the curve (AUC): 0.989"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AUC score of model trained with ROSE(generated data) data\n",
    "roc.curve(hacide.test$cls, test_rose_pred[, 2], plotit = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It seems like model trained with data generated from ROSE has the highest AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
